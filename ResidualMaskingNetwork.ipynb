{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DavidMachajewski/ResidualMaskingNetworkFER/blob/main/ResidualMaskingNetwork.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muS1dFyM8q5h"
      },
      "source": [
        "# Residual Masking Network\n",
        "\n",
        "This notebook uses the Residual Masking Network [1] for Facial Expression Recognition (FER). Their source code can be found on GitHub [2].\n",
        "\n",
        "[1] \"Facial Expression Recognition Using Residual Masking Network\", Pham et al.\n",
        "\n",
        "[2] ResMaskingNet implementation, GitHub: https://github.com/phamquiluan/ResidualMaskingNetwork\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zivJNm_1Ssme"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVKDdPdD2yMq"
      },
      "source": [
        "**Install missing packages**\n",
        "\n",
        "Run the following cell to install the typing package, which is needed for using type hinting and the rmn packages, which is the implementation of the resmaskingnet, see resource [2]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "id": "h5J2PoLS2X4Z",
        "outputId": "b1c62e70-d9e8-4d87-ceda-16b386ab307b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rmn\n",
            "  Downloading rmn-3.0.2-py3-none-any.whl (109 kB)\n",
            "\u001b[K     |████████████████████████████████| 109 kB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from rmn) (2.23.0)\n",
            "Collecting pytorchcv\n",
            "  Downloading pytorchcv-0.0.67-py2.py3-none-any.whl (532 kB)\n",
            "\u001b[K     |████████████████████████████████| 532 kB 39.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from rmn) (4.62.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from rmn) (4.1.2.30)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from rmn) (1.19.5)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from rmn) (0.11.1+cu111)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from rmn) (1.10.0+cu111)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->rmn) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->rmn) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->rmn) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->rmn) (2021.10.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->rmn) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->rmn) (7.1.2)\n",
            "Installing collected packages: pytorchcv, rmn\n",
            "Successfully installed pytorchcv-0.0.67 rmn-3.0.2\n",
            "Collecting typing\n",
            "  Downloading typing-3.7.4.3.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 3.5 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: typing\n",
            "  Building wheel for typing (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for typing: filename=typing-3.7.4.3-py3-none-any.whl size=26324 sha256=f21743392fcf27f718397b2acaa72ad49aa3d5f5ea212e3a9987a235dee740b9\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/f3/15/01aa6571f0a72ee6ae7b827c1491c37a1f72d686fd22b43b0e\n",
            "Successfully built typing\n",
            "Installing collected packages: typing\n",
            "Successfully installed typing-3.7.4.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "typing"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install rmn\n",
        "!pip install typing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIDzfjJLO-fm"
      },
      "source": [
        "**Uploading dataset**\n",
        "\n",
        "Import the dataset to the colab runtime using the wget command or the upload option. \n",
        "In case of the JAFFE dataset we load it as a zipped \"dataset\" folder. It takes just between 2 and 5 minutes as its a small dataset.\n",
        "\n",
        "*NOTE*: \n",
        "*The \"jaffe.zip\" should contain a \"dataset\" folder, with all JAFFE images inside, as the collectors provide.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "L4iSyEw7K8Vd",
        "outputId": "0d194250-a467-4114-c518-e6d7b7ad12dc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-39b0d4f9-c095-4b78-9a14-b242edb106bc\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-39b0d4f9-c095-4b78-9a14-b242edb106bc\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving jaffe.zip to jaffe.zip\n",
            "Archive:  /content/jaffe.zip\n",
            "warning:  /content/jaffe.zip appears to use backslashes as path separators\n",
            "  inflating: /content/jaffe/dataset/KA.AN1.39.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.AN2.40.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.AN3.41.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.DI1.42.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.DI2.43.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.DI3.44.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.FE1.45.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.FE2.46.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.FE3.47.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.FE4.48.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.HA1.29.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.HA2.30.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.HA3.31.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.HA4.32.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.NE1.26.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.NE2.27.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.NE3.28.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SA1.33.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SA2.34.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SA3.35.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SU1.36.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SU2.37.tiff  \n",
            "  inflating: /content/jaffe/dataset/KA.SU3.38.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.AN1.167.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.AN2.168.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.AN3.169.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.DI1.170.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.DI2.171.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.DI3.172.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.DI4.173.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.FE1.174.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.FE2.175.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.FE3.176.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.HA1.158.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.HA2.159.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.HA3.160.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.NE1.155.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.NE2.156.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.NE3.157.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SA1.161.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SA2.162.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SA3.163.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SU1.164.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SU2.165.tiff  \n",
            "  inflating: /content/jaffe/dataset/KL.SU3.166.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.AN1.17.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.AN2.18.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.AN3.19.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.DI1.20.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.DI3.22.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.FE1.23.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.FE2.24.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.FE3.25.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.HA1.4.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.HA2.5.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.HA3.6.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.HA4.7.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.NE1.1.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.NE2.2.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.NE3.3.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SA1.9.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SA2.10.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SA3.11.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SA5.13.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SU1.14.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SU2.15.tiff  \n",
            "  inflating: /content/jaffe/dataset/KM.SU3.16.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.AN1.83.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.AN2.84.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.AN3.85.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.DI1.86.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.DI2.87.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.DI3.88.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.FE1.89.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.FE2.90.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.FE3.91.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.HA1.74.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.HA2.75.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.NE1.71.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.NE2.72.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.NE3.73.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SA1.77.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SA2.78.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SA3.79.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SU1.80.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SU2.81.tiff  \n",
            "  inflating: /content/jaffe/dataset/KR.SU3.82.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.AN1.125.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.AN2.126.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.AN3.127.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.DI1.128.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.DI2.129.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.DI3.130.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.FE1.131.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.FE2.132.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.FE3.133.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.HA1.116.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.HA2.117.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.HA3.118.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.NE1.113.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.NE2.114.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.NE3.115.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SA1.119.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SA2.120.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SA3.121.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SU1.122.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SU2.123.tiff  \n",
            "  inflating: /content/jaffe/dataset/MK.SU3.124.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.AN1.211.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.AN2.212.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.AN3.213.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.DI1.214.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.DI2.215.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.DI3.216.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.FE1.217.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.FE2.218.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.FE3.219.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.HA1.202.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.HA2.203.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.HA3.204.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.NE1.199.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.NE2.200.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.NE3.201.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SA1.205.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SA2.206.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SA3.207.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SU1.208.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SU2.209.tiff  \n",
            "  inflating: /content/jaffe/dataset/NA.SU3.210.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.AN1.104.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.AN2.105.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.AN3.106.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.DI1.107.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.DI3.109.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.FE1.110.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.FE2.111.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.FE3.112.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.HA1.95.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.HA2.96.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.HA3.97.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.NE1.92.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.NE2.93.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.NE3.94.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SA1.98.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SA2.99.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SA3.100.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SU1.101.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SU2.102.tiff  \n",
            "  inflating: /content/jaffe/dataset/NM.SU3.103.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.AN1.190.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.AN2.191.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.AN3.192.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.DI1.193.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.DI2.194.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.DI3.195.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.FE1.196.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.FE2.197.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.FE3.198.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.HA1.180.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.HA2.181.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.HA3.182.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.NE1.177.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.NE2.178.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.NE3.179.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SA1.184.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SA2.185.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SA3.186.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SU1.187.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SU2.188.tiff  \n",
            "  inflating: /content/jaffe/dataset/TM.SU3.189.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.AN1.146.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.AN2.147.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.AN3.148.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.DI1.149.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.DI2.150.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.DI3.151.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.FE1.152.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.FE2.153.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.FE3.154.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.HA1.137.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.HA2.138.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.HA3.139.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.NE1.134.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.NE2.135.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.NE3.136.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SA1.140.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SA2.141.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SA3.142.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SU1.143.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SU2.144.tiff  \n",
            "  inflating: /content/jaffe/dataset/UY.SU3.145.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.AN1.61.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.AN2.62.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.AN3.63.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.DI1.64.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.DI2.65.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.DI3.66.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.FE1.67.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.FE2.68.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.FE3.69.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.FE4.70.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.HA1.52.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.HA2.53.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.HA3.54.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.NE1.49.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.NE2.50.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.NE3.51.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SA1.55.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SA2.56.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SA3.57.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SU1.58.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SU2.59.tiff  \n",
            "  inflating: /content/jaffe/dataset/YM.SU3.60.tiff  \n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "dataset_raw = files.upload()\n",
        "!unzip \"/content/jaffe.zip\" -d \"/content/jaffe/\"\n",
        "# resulting folder is /content/jaffe/datast/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpZmEs3lH2MS"
      },
      "source": [
        "**Import mandatory libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcAbESPj5DFJ",
        "outputId": "d83e9354-bb22-4853-915e-80c39e51d2c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pretrained_ckpt does not exists!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading pretrained_ckpt..: 100%|██████████| 552M/552M [00:12<00:00, 44.9MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deploy.prototxt.txt does not exists!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading deploy.prototxt.txt..: 100%|██████████| 28.1k/28.1k [00:00<00:00, 7.38MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "res10_300x300_ssd_iter_140000.caffemodel does not exists!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading res10_300x300_ssd_iter_140000.caffemodel..: 100%|██████████| 212/212 [00:00<00:00, 77.4kiB/s]\n"
          ]
        }
      ],
      "source": [
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "from typing import Dict, NamedTuple, List, Union\n",
        "from skimage import transform\n",
        "from torchvision import transforms\n",
        "from rmn import RMN, models\n",
        "import numpy as np\n",
        "import torch\n",
        "import datetime\n",
        "import PIL\n",
        "import os\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch import nn\n",
        "import rmn\n",
        "from copy import deepcopy\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PwHk1RAYXOtS"
      },
      "source": [
        "Set the location of the jaffe dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOBe7-jYIN0L"
      },
      "outputs": [],
      "source": [
        "# this \"dataset_path\" object will be needed as input for the JAFFE class\n",
        "dataset_path = Path(Path.cwd() / \"jaffe\" / \"dataset\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U-XM4tXyWiQ8"
      },
      "outputs": [],
      "source": [
        "# optional download it from the server using your credentials\n",
        "\n",
        "# ###############\n",
        "#\n",
        "# add code here\n",
        "#\n",
        "# ###############"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VCn_TXh25ZeO"
      },
      "source": [
        "**Implementation of the JAFFE dataset and dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuENYkj9rk7f"
      },
      "outputs": [],
      "source": [
        "class Sample(dict):\n",
        "    \"\"\"Accessing dict keys by dot notation\"\"\"\n",
        "    __getattr__ = dict.get\n",
        "    __setattr__ = dict.__setitem__\n",
        "    __delattr__ = dict.__delitem__\n",
        "\n",
        "\n",
        "class JAFFE(torch.utils.data.Dataset):\n",
        "  \"\"\"Implementation of the JAFFE dataset by subclassing PyTorch's dataset class.\"\"\"\n",
        "  def __init__(self, path_to_dataset: Path, mode = None, split_dataset: float = None, transform: transforms=None):\n",
        "    \"\"\"\n",
        "    path_to_dataset:\n",
        "    transform:\n",
        "    \"\"\"\n",
        "    self._mode = mode\n",
        "    self._split_dataset = split_dataset\n",
        "    self._path_dataset: Path = path_to_dataset\n",
        "    self._dataset = [f for f in self._path_dataset.iterdir() if f.is_file()]\n",
        "    # get train, test and validation split of image paths\n",
        "    self._path_images_train, self._path_images_test, self._path_images_val = self._split(self._dataset, 0.5, self._split_dataset)\n",
        "    print(f\"inside init function: train {len(self._path_images_train)}, test {len(self._path_images_test)}\")\n",
        "    self._path_images = None\n",
        "    self._transform = transform\n",
        "    self._classes = {'AN': 0, 'DI': 1, 'FE': 2, 'HA': 3, 'SA': 4, 'SU': 5, 'NE': 6}\n",
        "\n",
        "  def get_split(self, mode: str):\n",
        "    \"\"\" Return the training, testing or validation JAFFE dataset\n",
        "    :mode: \"train\", \"test\", \"val\"\n",
        "    return: JAFFE dataset\n",
        "    \"\"\"\n",
        "    print(f\"Returning {mode}-set.\")\n",
        "    self._mode = mode\n",
        "    if mode == \"train\":\n",
        "      self._path_images = self._path_images_train\n",
        "      new_instance = deepcopy(self)\n",
        "    elif mode == \"test\":\n",
        "      self._path_images = self._path_images_test\n",
        "      new_instance = deepcopy(self)\n",
        "    elif mode == \"val\":\n",
        "      self._path_images = self._path_images_val\n",
        "      new_instance = deepcopy(self)\n",
        "    return new_instance\n",
        "\n",
        "  def _split(self, dataset: List, testval = 0.5, split_dataset = 0.8):\n",
        "    \"\"\"Splits the image paths into train, test image paths\n",
        "    split_dataset: Has to be a float in range [0.0, 1.0]\n",
        "    test_val: splits the test set into test/val of same size\"\"\"\n",
        "    lendata = len(dataset)\n",
        "    np.random.shuffle(dataset)\n",
        "\n",
        "    train_amount = split_dataset\n",
        "\n",
        "    bound = int(train_amount * lendata)\n",
        "    train, test = dataset[:bound], dataset[bound:]\n",
        "    len_testset = len(test)\n",
        "    newtest, val = test[:int(testval * len_testset)], test[int(testval * len_testset):]\n",
        "\n",
        "    return train, newtest, val\n",
        "\n",
        "  def show_sample(self, idx: int):\n",
        "    \"\"\"Given a index idx this function shows the corresponding image sample\"\"\"\n",
        "    with Image.open(self._path_images[idx]) as img:\n",
        "      display(img)\n",
        "  \n",
        "  def _load_image(self, path: Path):\n",
        "    \"\"\"Load image using path and returns this image as np.Array\"\"\"\n",
        "    image = PIL.Image.open(path)\n",
        "    image = transforms.Grayscale(num_output_channels=3)(image)\n",
        "    return image\n",
        "  \n",
        "  def _get_label(self, filepath: Path) -> str:\n",
        "    \"\"\"Extracts label from the filename of an JAFFE image sample\"\"\"\n",
        "    return filepath.stem.split(\".\")[1][:2]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self._path_images)\n",
        "  \n",
        "  def __getitem__(self, idx: int) -> Sample:\n",
        "    tmp_path = self._path_images[idx]\n",
        "\n",
        "    sample = Sample({\n",
        "        \"image\": self._load_image(tmp_path), \n",
        "        \"label\": self._classes[self._get_label(tmp_path)]})\n",
        "\n",
        "    if self._transform:\n",
        "      sample = self._transform(sample)\n",
        "\n",
        "    return sample\n",
        "\n",
        "    def _download():\n",
        "      \"\"\"...\"\"\"\n",
        "      pass\n",
        "\n",
        "\n",
        "class Scale(object):\n",
        "  def __init__(self, new_size: List[Union[int, int]]):\n",
        "    self.new_size = new_size\n",
        "  \n",
        "  def __call__(self, sample: Sample) -> Sample:\n",
        "    h, w = self.new_size\n",
        "    # sample.image = transform.resize(sample.image, (h, w))\n",
        "    sample.image = transforms.Resize(size=(h,w))(sample.image)\n",
        "    return sample\n",
        "\n",
        "\n",
        "class ToTensor(object):\n",
        "  def __call__(self, sample: Sample) -> Sample:\n",
        "    # sample.image = np.asarray(sample.image)[:, :, np.newaxis]\n",
        "    # from H x W x C to C x H x W\n",
        "    sample.image = torch.from_numpy(np.asarray(sample.image))\n",
        "    # sample.image = torch.unsqueeze(sample.image, 2)\n",
        "    sample.image = sample.image.permute((2, 0, 1))\n",
        "    # sample.image = torch.unsqueeze(sample.image, 2)\n",
        "    sample.image = sample.image.float()\n",
        "    sample.label = sample.label # torch.Tensor(sample.label)\n",
        "    return sample\n",
        "\n",
        "\n",
        "def get_transforms(new_size: List[Union[int, int]]):\n",
        "  transformer = transforms.Compose([\n",
        "       Scale(new_size),\n",
        "       ToTensor()])\n",
        "  return transformer\n",
        "\n",
        "\n",
        "def JAFFE_dataloader(path_to_dataset: Path, split_dataset, transforms_new_size):\n",
        "  \"\"\"Instantiate the jaffe class and return a PyTorch Dataloader.\"\"\"\n",
        "  transformer = get_transforms(transforms_new_size)\n",
        "  dataset = JAFFE(path_to_dataset=path_to_dataset,\n",
        "                  mode=None,\n",
        "                  split_dataset=0.8,\n",
        "                  transform=transformer)\n",
        "\n",
        "  trainset = dataset.get_split(\"train\")\n",
        "  testset = dataset.get_split(\"test\")\n",
        "  valset = dataset.get_split(\"val\")\n",
        "\n",
        "  print(f\"created trainset of size: {len(trainset)}\")\n",
        "  print(f\"created testset of size: {len(testset)}\")\n",
        "  print(f\"created valset of size: {len(valset)}\")\n",
        "\n",
        "  traindl = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=1, drop_last=True)\n",
        "  testdl = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=True, num_workers=1, drop_last=True)\n",
        "  valdl = torch.utils.data.DataLoader(valset, batch_size=4, shuffle=True, num_workers=1, drop_last=True)\n",
        "  return traindl, testdl, valdl"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBpXKrTat_EF"
      },
      "source": [
        "**Instantiate the JAFFE dataloader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIUsB4Mv5p4o",
        "outputId": "a4dd1926-b56f-4a2a-cffd-0e84f76041ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "inside init function: train 170, test 21\n",
            "Returning train-set.\n",
            "Returning test-set.\n",
            "Returning val-set.\n",
            "created trainset of size: 170\n",
            "created testset of size: 21\n",
            "created valset of size: 22\n"
          ]
        }
      ],
      "source": [
        "#\n",
        "# make \"transform_new_size\" dependend on the .json config file\n",
        "#\n",
        "\n",
        "traindl, testdl, valdl = JAFFE_dataloader(path_to_dataset=dataset_path, split_dataset = 0.8, transforms_new_size=[224, 224])\n",
        "\n",
        "#for idx, batch in enumerate(traindl):\n",
        "#  if idx==0:\n",
        "#    print(batch['image'].shape)\n",
        "#    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GQ2HpcEY8Bp"
      },
      "source": [
        "**Coding the JAFFE trainer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O-VefWodY6tV"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target):\n",
        "    with torch.no_grad():\n",
        "        batch_size = target.size(0)\n",
        "        pred = torch.argmax(output, dim=1)\n",
        "        correct = pred.eq(target).float().sum(0)\n",
        "        acc = correct * 100 / batch_size\n",
        "    return [acc]\n",
        "\n",
        "\n",
        "class JAFFETrainer():\n",
        "  def __init__(self, model, train_set, val_set, test_set, configs):\n",
        "    \"\"\"\n",
        "    :train_set: dataloader of the train set\n",
        "    :val_set: dataloader of the validation set\n",
        "    :test_set: dataloader of the test set\n",
        "    \"\"\"\n",
        "    # print start and configs\n",
        "    #\n",
        "    # load configurations like the author defines\n",
        "    self._configs = configs\n",
        "    self._configs = configs\n",
        "    self._lr = self._configs[\"lr\"]\n",
        "    self._batch_size = self._configs[\"batch_size\"]\n",
        "    self._momentum = self._configs[\"momentum\"]\n",
        "    self._weight_decay = self._configs[\"weight_decay\"]\n",
        "    self._distributed = self._configs[\"distributed\"]\n",
        "    self._num_workers = self._configs[\"num_workers\"]\n",
        "    self._device = torch.device(self._configs[\"device\"])\n",
        "    self._max_epoch_num = self._configs[\"max_epoch_num\"]\n",
        "    self._max_plateau_count = self._configs[\"max_plateau_count\"]\n",
        "    # model\n",
        "    self._model = model(in_channels=configs[\"in_channels\"], num_classes=configs[\"num_classes\"])\n",
        "    \n",
        "    self._model.to(self._device)\n",
        "    # datasets\n",
        "    self._train_loader = train_set\n",
        "    self._test_loader = test_set\n",
        "    self._val_loader = val_set\n",
        "    # Loss and optimizer\n",
        "    self._criterion = nn.CrossEntropyLoss().to(self._device)\n",
        "    self._optimizer = torch.optim.Adam(params=self._model.parameters(),\n",
        "                                       lr=self._lr,\n",
        "                                       weight_decay=self._weight_decay)\n",
        "    self._scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer=self._optimizer, \n",
        "                                                                 patience=self._configs[\"plateau_patience\"],\n",
        "                                                                 min_lr=1e-6, \n",
        "                                                                 verbose=True)\n",
        "    \n",
        "    # training info\n",
        "    self._start_time = datetime.datetime.now()\n",
        "    self._start_time = self._start_time.replace(microsecond=0)\n",
        "\n",
        "    log_dir = os.path.join(\n",
        "        self._configs[\"cwd\"],\n",
        "        self._configs[\"log_dir\"],\n",
        "        \"{}_{}\".format(\n",
        "            self._configs[\"model_name\"], self._start_time.strftime(\"%Y%b%d_%H.%M\")\n",
        "        ),\n",
        "    )\n",
        "\n",
        "    self._writer = SummaryWriter(log_dir)\n",
        "    self._train_loss = []\n",
        "    self._train_acc = []\n",
        "    self._val_loss = []\n",
        "    self._val_acc = []\n",
        "    self._best_loss = 1e9\n",
        "    self._best_acc = 0\n",
        "    self._test_acc = 0.0\n",
        "    self._plateau_count = 0\n",
        "    self._current_epoch_num = 0\n",
        "\n",
        "    # for checkpoints\n",
        "    self._checkpoint_dir = os.path.join(self._configs[\"cwd\"], \"saved/checkpoints\")\n",
        "    if not os.path.exists(self._checkpoint_dir):\n",
        "        os.makedirs(self._checkpoint_dir, exist_ok=True)\n",
        "\n",
        "    self._checkpoint_path = os.path.join(\n",
        "        self._checkpoint_dir,\n",
        "        \"{}_{}\".format(\n",
        "            self._configs[\"model_name\"], self._start_time.strftime(\"%Y%b%d_%H.%M\")\n",
        "        ),\n",
        "    )\n",
        "  \n",
        "  def _train(self):\n",
        "    # print(\"training step\")\n",
        "    self._model.train()\n",
        "    train_loss, train_acc = 0.0, 0.0\n",
        "\n",
        "    for i, batch in tqdm(enumerate(self._train_loader), total=len(self._train_loader), leave=False):\n",
        "      # print(f\"size of train loader: {len(self._train_loader)}\")\n",
        "      images = batch[\"image\"]  # .to(self._device)\n",
        "      # print(f\"shape of image tensor: {images.shape}\")\n",
        "      targets = batch[\"label\"]  # tensor? .to ...\n",
        "\n",
        "      outputs = self._model(images)\n",
        "\n",
        "      loss = self._criterion(outputs, targets)\n",
        "      acc = accuracy(outputs, targets)[0]\n",
        "\n",
        "      train_loss += loss.item()\n",
        "      train_acc += acc.item()\n",
        "\n",
        "      self._optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self._optimizer.step()\n",
        "    \n",
        "    i += 1\n",
        "    self._train_loss.append(train_loss / i)\n",
        "    self._train_acc.append(train_acc / i)\n",
        "  \n",
        "  def _val(self):\n",
        "    print(\"validation\")\n",
        "    self._model.eval()\n",
        "    val_loss, val_acc = 0.0, 0.0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      for i, batch in tqdm(enumerate(self._val_loader), total=len(self._val_loader), leave=False):\n",
        "        images = batch[\"image\"]  # .cuda(non_blocking=True)\n",
        "        targets = batch[\"label\"]  #.cuda(non_blocking=True)\n",
        "\n",
        "        # compute output, measure accuracy and record loss\n",
        "        outputs = self._model(images)\n",
        "\n",
        "        loss = self._criterion(outputs, targets)\n",
        "        acc = accuracy(outputs, targets)[0]\n",
        "\n",
        "        val_loss += loss.item()\n",
        "        val_acc += acc.item()\n",
        "\n",
        "      i += 1\n",
        "      self._val_loss.append(val_loss / i)\n",
        "      self._val_acc.append(val_acc / i)\n",
        "  \n",
        "  def _increase_epoch_num(self):\n",
        "    self._current_epoch_num += 1\n",
        "  \n",
        "  def _is_stop(self):\n",
        "    return (\n",
        "      self._plateau_count > self._max_plateau_count\n",
        "      or self._current_epoch_num > self._max_epoch_num\n",
        "    )\n",
        "\n",
        "  def _update_training_state(self):\n",
        "    if self._val_acc[-1] > self._best_acc:\n",
        "      self._save_weights()\n",
        "      self._plateau_count = 0\n",
        "      self._best_acc = self._val_acc[-1]\n",
        "      self._best_loss = self._val_loss[-1]\n",
        "    else:\n",
        "      self._plateau_count += 1\n",
        "\n",
        "    self._scheduler.step(100 - self._val_acc[-1])  \n",
        "\n",
        "  def _save_weights(self, test_acc=0.0):\n",
        "    if self._distributed == 0:\n",
        "      state_dict = self._model.state_dict()\n",
        "    else:\n",
        "      state_dict = self._model.module.state_dict()\n",
        "\n",
        "    state = {\n",
        "        **self._configs,\n",
        "        \"net\": state_dict,\n",
        "        \"best_loss\": self._best_loss,\n",
        "        \"best_acc\": self._best_acc,\n",
        "        \"train_losses\": self._train_loss,\n",
        "        \"val_loss\": self._val_loss,\n",
        "        \"train_acc\": self._train_acc,\n",
        "        \"val_acc\": self._val_acc,\n",
        "        \"test_acc\": self._test_acc,\n",
        "      }\n",
        "    torch.save(state, self._checkpoint_path)\n",
        "\n",
        "  def _logging(self):\n",
        "    consume_time = str(datetime.datetime.now() - self._start_time)\n",
        "\n",
        "    message = \"\\nE{:03d}  {:.3f}/{:.3f}/{:.3f} {:.3f}/{:.3f}/{:.3f} | p{:02d}  Time {}\\n\".format(\n",
        "      self._current_epoch_num,\n",
        "      self._train_loss[-1],\n",
        "      self._val_loss[-1],\n",
        "      self._best_loss,\n",
        "      self._train_acc[-1],\n",
        "      self._val_acc[-1],\n",
        "      self._best_acc,\n",
        "      self._plateau_count,\n",
        "      consume_time[:-7],\n",
        "    )\n",
        "\n",
        "    self._writer.add_scalar(\n",
        "        \"Accuracy/Train\", self._train_acc[-1], self._current_epoch_num\n",
        "    )\n",
        "    self._writer.add_scalar(\n",
        "        \"Accuracy/Val\", self._val_acc[-1], self._current_epoch_num\n",
        "    )\n",
        "    self._writer.add_scalar(\n",
        "        \"Loss/Train\", self._train_loss[-1], self._current_epoch_num\n",
        "    )\n",
        "    self._writer.add_scalar(\"Loss/Val\", self._val_loss[-1], self._current_epoch_num)\n",
        "\n",
        "    print(message)\n",
        "  \n",
        "  def _load_ckp(self):\n",
        "    \"\"\"Test\"\"\"\n",
        "    pass\n",
        "\n",
        "  def train(self):\n",
        "    print(\"start training\")\n",
        "    # print(self._model)\n",
        "    while not self._is_stop():\n",
        "      self._increase_epoch_num()\n",
        "      self._train()\n",
        "      self._val()\n",
        "\n",
        "      self._update_training_state()\n",
        "      self._logging()\n",
        "  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzR949EaxJv_"
      },
      "source": [
        "**Training the Residual Masking Network on JAFFE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lfbu8momu9nx",
        "outputId": "5eb36c09-9867-48ba-f74d-5f23613ddfa1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SIZE, amount of batches of traindl: 42\n",
            "SIZE, amount of batches of testdl: 5\n",
            "SIZE, amount of batches of valdl: 5\n",
            "start training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E001  1.992/1.856/1.856 18.452/30.000/30.000 | p00  Time 0:08:50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E002  1.678/1.796/1.856 31.548/25.000/30.000 | p01  Time 0:17:48\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E003  1.344/1.956/1.856 47.024/25.000/30.000 | p02  Time 0:26:49\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     4: reducing learning rate of group 0 to 1.0000e-05.\n",
            "\n",
            "E004  1.118/4.686/1.856 62.500/30.000/30.000 | p03  Time 0:35:42\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E005  0.969/0.800/0.800 66.071/70.000/70.000 | p00  Time 0:44:37\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E006  0.753/0.616/0.616 74.405/80.000/80.000 | p00  Time 0:53:25\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E007  0.518/0.693/0.616 85.714/75.000/80.000 | p01  Time 1:02:18\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E008  0.404/0.591/0.616 91.071/70.000/80.000 | p02  Time 1:11:26\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch     9: reducing learning rate of group 0 to 1.0000e-06.\n",
            "\n",
            "E009  0.339/0.613/0.616 92.262/70.000/80.000 | p03  Time 1:20:35\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E010  0.240/0.638/0.616 96.429/70.000/80.000 | p04  Time 1:29:34\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E011  0.396/0.519/0.616 89.286/80.000/80.000 | p05  Time 1:38:36\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E012  0.264/0.576/0.576 94.048/85.000/85.000 | p00  Time 1:47:32\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E013  0.294/0.636/0.576 94.048/75.000/85.000 | p01  Time 1:56:19\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E014  0.269/0.461/0.576 92.857/85.000/85.000 | p02  Time 2:05:15\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E015  0.279/0.590/0.576 94.048/80.000/85.000 | p03  Time 2:14:16\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E016  0.256/0.576/0.576 92.857/75.000/85.000 | p04  Time 2:23:11\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E017  0.282/0.656/0.576 93.452/70.000/85.000 | p05  Time 2:32:03\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E018  0.325/0.633/0.576 91.667/75.000/85.000 | p06  Time 2:40:50\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E019  0.353/0.509/0.576 90.476/80.000/85.000 | p07  Time 2:49:43\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                             "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E020  0.228/0.648/0.576 97.619/70.000/85.000 | p08  Time 2:58:31\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/42 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n",
            "                                               "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "validation\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/5 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:110: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ../torch/csrc/utils/tensor_numpy.cpp:189.)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "E021  0.253/0.604/0.576 94.048/75.000/85.000 | p09  Time 3:07:24\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# config file for JAFFE\n",
        "train_config = {\n",
        "\t\"data_path\": \"content/jaffe/dataset/\",\n",
        "\t\"image_size\": 224,\n",
        "\t\"in_channels\": 3,\n",
        "\t\"num_classes\": 7,\n",
        "\t\"arch\": \"resmasking_dropout1\", # alexnet\n",
        "\t\"lr\":  0.0001,\n",
        "\t\"weighted_loss\": 0,\n",
        "\t\"momentum\": 0.9,\n",
        "\t\"weight_decay\": 0.001,\n",
        "\t\"distributed\": 0,\n",
        "\t\"batch_size\": 16, \n",
        "  \"num_workers\": 8,\n",
        "  \"device\": \"cpu\",\n",
        "  \"max_epoch_num\": 50,\n",
        "  \"max_plateau_count\": 8,\n",
        "  \"plateau_patience\": 2,\n",
        "  \"steplr\": 50,\n",
        "  \"log_dir\": \"log\",\n",
        "  \"checkpoint_dir\": \"checkpoint/\",\n",
        "  \"model_name\": \"test\",\n",
        "  \"cwd\": \"content/\"\n",
        "}\n",
        "\n",
        "train_config2 = {\n",
        "\t\"image_size\": 224,\n",
        "\t\"in_channels\": 3,\n",
        "\t\"num_classes\": 8,\n",
        "\t\"arch\": \"resmasking_dropout1\",\n",
        "\t\"lr\":  0.0001,\n",
        "\t\"momentum\": 0.9,\n",
        "\t\"weight_decay\": 1e-3,\n",
        "\t\"distributed\": 0,\n",
        "\t\"batch_size\": 10,\n",
        "\t\"num_workers\": 5,\n",
        "\t\"device\": \"cpu\", #\"cuda:0\",\n",
        "\t\"max_epoch_num\": 100000,\n",
        "\t\"max_plateau_count\": 20,\n",
        "\t\"plateau_patience\": 4,\n",
        "\t\"steplr\": 50,\n",
        "\t\"log_dir\": \"saved/logs\",\n",
        "\t\"checkpoint_dir\": \"saved/checkpoints\",\n",
        "\t\"model_name\": \"aug\",\n",
        "  \"cwd\": \"content/\"\n",
        "}\n",
        "\n",
        "def train(train_config):\n",
        "\n",
        "  model = models.__dict__[train_config[\"arch\"]]\n",
        "\n",
        "  # load train, test, val data traindl, testdl, valdl\n",
        "  print(f\"SIZE, amount of batches of traindl: {len(traindl)}\")\n",
        "  print(f\"SIZE, amount of batches of testdl: {len(testdl)}\")\n",
        "  print(f\"SIZE, amount of batches of valdl: {len(valdl)}\")\n",
        "  trainer = JAFFETrainer(model=model, train_set=traindl, val_set=valdl, test_set=testdl, configs=train_config)\n",
        "  trainer.train()\n",
        "\n",
        "\n",
        "train(train_config)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "ResidualMaskingNetwork.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyP0lfCopNJO1luEYqFLikCk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}